{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1d9f92f1",
   "metadata": {},
   "source": [
    "!pip install gym[classic_control]\n",
    "!pip install pyglet\n",
    "!sudo apt-get install -y python-opengl > /dev/null 2>&1\n",
    "!pip install git+https://github.com/tensorflow/docs > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d66829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 10:44:52.670898: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1920928955078125e-07\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import gym\n",
    "import numpy as np\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from typing import Any, List, Sequence, Tuple\n",
    "\n",
    "# Create the Environment -> Premade thing in the gym library\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# Set a seed for environment reproductivity\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Small Epsilon value for stablizing division operations\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "print(eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de71eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 10:44:55.612128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "class ActorCritic(tf.keras.Model):\n",
    "                          \n",
    "    # Basically all this class does is just initializes a basic neural network model that takes in as input the units for complexity and the amount of actions that the model is able to take\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_actions: int,\n",
    "        num_hidden_units: int):\n",
    "                  \n",
    "        super().__init__()\n",
    "                  \n",
    "        self.common = layers.Dense(num_hidden_units, activation='relu')\n",
    "        self.actor = layers.Dense(num_actions)\n",
    "        self.critic = layers.Dense(1)\n",
    "                  \n",
    "    def call(self, inputs: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "        \n",
    "        x = self.common(inputs)\n",
    "        return self.actor(x), self.critic(x)\n",
    "                  \n",
    "                  \n",
    "num_actions = env.action_space.n  # Basically the amount of actions that the RL Agent has (which is 2 because it can either move the cart left or right\n",
    "print(num_actions)\n",
    "num_hidden_units = 128 # Just represents the complexity of the neural network\n",
    "\n",
    "model = ActorCritic(num_actions, num_hidden_units)                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea23c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_step(action: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    # this is used for compatibility purposes with Tensorflows' graph \n",
    "    # Also returns state, done, and reward variables given an action\n",
    "    \n",
    "    state, reward, done, truncated, info = env.step(action)\n",
    "    return (state.astype(np.float32),\n",
    "            np.array(reward, np.int32),\n",
    "            np.array(done, np.int32))\n",
    "\n",
    "def tf_env_step(action: tf.Tensor) -> List[tf.Tensor]:\n",
    "    return tf.numpy_function(env_step, [action], [tf.float32, tf.int32, tf.int32])\n",
    "\n",
    "# This function creates training data by running a single trial run\n",
    "def run_episode(\n",
    "    initial_state: tf.Tensor,\n",
    "    model: tf.keras.Model,\n",
    "    max_steps: int) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "    \n",
    "    # Create arrays that values will go into\n",
    "    action_probs = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    values = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    rewards = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
    "    \n",
    "    initial_state_shape = initial_state.shape\n",
    "    state = initial_state\n",
    "    \n",
    "    for i in tf.range(max_steps):\n",
    "        # We convert the state so that it can be used in the model function one time. I think we make it batched, so that the model only runs it one time\n",
    "        state = tf.expand_dims(state, 0)\n",
    "        \n",
    "        # Test the model on the current state\n",
    "        action_logits_t, value = model(state)\n",
    "        \n",
    "        # We take a random action based on what the model spits out\n",
    "        action = tf.random.categorical(action_logits_t, 1)[0, 0]\n",
    "        action_probs_t = tf.nn.softmax(action_logits_t)\n",
    "        \n",
    "        values = values.write(t, tf.squeeze(value))\n",
    "        \n",
    "        actions_probs = action_probs.write(t, actions_probs_t[0, action])\n",
    "        \n",
    "        # Extract the state, reward, and whether or not it is done from the action (if it is, then the loop breaks)\n",
    "        state, reward, done = tf_env_step(action)\n",
    "        state.set_shape(initial_state_shape)\n",
    "\n",
    "        rewards = rewards.write(t, reward)\n",
    "        \n",
    "        if tf.cast(done, tf.bool):\n",
    "            break\n",
    "            \n",
    "    action_probs = action_probs.stack()\n",
    "    values = values.stack()\n",
    "    rewards = rewards.stack()\n",
    "    \n",
    "    return action_probs, values, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9433dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_return(rewards: tf.Tensor, gamma: float, standardize: bool = True) -> tf.Tensor:\n",
    "    # This function computes the expected return in each timestep\n",
    "    \n",
    "    n = tf.shape(rewards)[0] # Gets the amount of timesteps\n",
    "    returns = tf.TensorArray(dtype=tf.float32, size=n) # Creates a 'returns' variable with size equal to timesteps\n",
    "    \n",
    "    rewards = tf.cast(rewards[::-1], dtype=tf.float32)\n",
    "    discounted_sum = tf.constant(0.0)\n",
    "    discounted_sum_shape = discounted_sum.shape\n",
    "    for i in tf.range(n):\n",
    "        reward = rewards[i]\n",
    "        discounted_sum = reward + gamma * discounted_sum\n",
    "        discounted_sum.set_shape(discounted_sum_shape)\n",
    "        returns = returns.write(i, discounted_sum)\n",
    "    returns = returns.stack()[::-1]\n",
    "    \n",
    "    if standardize:\n",
    "        returns = ((returns - tf.math.reduce_mean(returns)) / (tf.math.reduce_std(returns) + eps))\n",
    "        \n",
    "    return returns\n",
    "    \n",
    "huber_loss = tf.keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
    "\n",
    "def compute_loss(action_probs: tf.Tensor, values: tf.Tensor, returns: tf.Tensor) -> tf.Tensor:\n",
    "    \n",
    "    advantage = returns - values\n",
    "    \n",
    "    action_log_probs = tf.math.log(action_probs)\n",
    "    actor_loss = -tf.math.reduce_sum(action_log_probs * advantage)\n",
    "    \n",
    "    critic_loss = huber_loss(values, returns)\n",
    "    \n",
    "    return actor_loss + critic_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad21df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "@tf.function\n",
    "def train_step(initial_state: tf.Tensor, model: tf.keras.Model, \n",
    "               optimizer: tf.keras.optimizers.Optimizer, gamma: float, max_steps_per_episode: int) -> tf.Tensor:\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        action_probs, values, rewards = run_episode(initial_state, model, max_steps_per_episode)\n",
    "        \n",
    "        returns = get_expected_returns(rewards, gamma)\n",
    "        \n",
    "        action_probs, values, returns = [tf.expand_dims(x, 1) for x in [action_probs, values, returns]]\n",
    "        \n",
    "        loss = compute_loss(action_probs, values, returns)\n",
    "        \n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    episode_reward = tf.math.reduce_sum(rewards)\n",
    "    \n",
    "    return episode_reward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d9cced7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"/var/folders/ph/5mp9dxqj3yx_w5c5mknynk780000gn/T/ipykernel_37699/4196616594.py\", line 8, in train_step  *\n        action_probs, values, rewards = run_episode(initial_state, model, max_steps_per_episode)\n    File \"/var/folders/ph/5mp9dxqj3yx_w5c5mknynk780000gn/T/ipykernel_37699/1098922951.py\", line 38, in run_episode  *\n        values = values.write(t, tf.squeeze(value))\n    File \"/Users/noahspurr/opt/anaconda3/lib/python3.9/site-packages/tqdm/utils.py\", line 84, in __ge__\n        return not self < other\n    File \"/Users/noahspurr/opt/anaconda3/lib/python3.9/site-packages/tqdm/utils.py\", line 69, in __lt__\n        return self._comparable < other._comparable\n\n    AttributeError: 'Tensor' object has no attribute '_comparable'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/ph/5mp9dxqj3yx_w5c5mknynk780000gn/T/__autograph_generated_filex9706gf_.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(initial_state, model, optimizer, gamma, max_steps_per_episode)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_episode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_steps_per_episode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                     \u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_expected_returns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/ph/5mp9dxqj3yx_w5c5mknynk780000gn/T/__autograph_generated_filefc7ozadq.py\u001b[0m in \u001b[0;36mtf__run_episode\u001b[0;34m(initial_state, model, max_steps)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'rewards'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'break_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'state'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'i'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                 \u001b[0maction_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/ph/5mp9dxqj3yx_w5c5mknynk780000gn/T/__autograph_generated_filefc7ozadq.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_logits_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0maction_probs_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_logits_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0mactions_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions_probs_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_env_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tqdm/utils.py\u001b[0m in \u001b[0;36m__ge__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__ge__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tqdm/utils.py\u001b[0m in \u001b[0;36m__lt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;34m\"\"\"Assumes child has self._comparable attr/@property\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__lt__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_comparable\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_comparable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__le__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/var/folders/ph/5mp9dxqj3yx_w5c5mknynk780000gn/T/ipykernel_37699/4196616594.py\", line 8, in train_step  *\n        action_probs, values, rewards = run_episode(initial_state, model, max_steps_per_episode)\n    File \"/var/folders/ph/5mp9dxqj3yx_w5c5mknynk780000gn/T/ipykernel_37699/1098922951.py\", line 38, in run_episode  *\n        values = values.write(t, tf.squeeze(value))\n    File \"/Users/noahspurr/opt/anaconda3/lib/python3.9/site-packages/tqdm/utils.py\", line 84, in __ge__\n        return not self < other\n    File \"/Users/noahspurr/opt/anaconda3/lib/python3.9/site-packages/tqdm/utils.py\", line 69, in __lt__\n        return self._comparable < other._comparable\n\n    AttributeError: 'Tensor' object has no attribute '_comparable'\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "min_episodes_criterion = 100\n",
    "max_episodes = 10000\n",
    "max_steps_per_episode = 500\n",
    "\n",
    "# `CartPole-v1` is considered solved if average reward is >= 475 over 500 \n",
    "# consecutive trials\n",
    "reward_threshold = 475\n",
    "running_reward = 0\n",
    "\n",
    "# Discount factor for future rewards\n",
    "gamma = 0.99\n",
    "\n",
    "episodes_reward: collections.deque = collections.deque(maxlen=min_episodes_criterion)\n",
    "    \n",
    "t = tqdm.trange(max_episodes)\n",
    "for i in t:\n",
    "    initial_state, info = env.reset()\n",
    "    initial_state = tf.constant(initial_state, dtype=tf.float32)\n",
    "    episode_reward = int(train_step(initial_state, model, optimizer, gamma, max_steps_per_episode))\n",
    "    \n",
    "    episodes_reward.append(episode_reward)\n",
    "    running_reward = statistics.mean(episodes_reward)\n",
    "    \n",
    "    t.set_postfix(episode_reward=episode_reward, running_reward=running_reward)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        pass\n",
    "    \n",
    "    if running_reward > reward_threshold and i >= min_episodes_criterion:\n",
    "        break\n",
    "        \n",
    "print(f'\\nSolved at episode {i}: average reward: {running_reward:.2f}!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "925ea52a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython import display as ipythondisplay\n",
    "from PIL import Image\n",
    "\n",
    "render_env = gym.make(\"CartPole-v1\", render_mode='rgb_array')\n",
    "\n",
    "def render_episode(env: gym.Env, model: tf.keras.Model, max_steps: int):\n",
    "    state, info = env.reset()\n",
    "    state = tf.constant(state, dtype=tf.float32)\n",
    "    screen = env.render()\n",
    "    images = [Image.fromarray(screen)]\n",
    "    \n",
    "    for i in range(1, max_steps + 1):\n",
    "        state = tf.expand_dims(state, 0)\n",
    "        action_probs, _ = model(state)\n",
    "        action = np.argmax(np.squeeze(action_probs))\n",
    "        \n",
    "        state, reward, done, truncated, info = env.step(action)\n",
    "        state = tf.constant(state, dtype=tf.float32)\n",
    "        \n",
    "        # Render Screen every 10 steps\n",
    "        if i % 10 == 0:\n",
    "            screen = env.render()\n",
    "            images.append(Image.fromarray(screen))\n",
    "            \n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    return images\n",
    "\n",
    "images = render_episode(render_env, model, max_steps_per_episode)\n",
    "image_file = 'cartpole-v1.gif'\n",
    "\n",
    "# loop=0: loop forever, duration=1: play each frame for 1ms\n",
    "images[0].save(image_file, save_all=True, append_images=images[1:], loop=0, duration=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b37acbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/gif;base64,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\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(image_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
